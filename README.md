# Creating an automated system that scrapes LinkedIn to analyze the top skills required for desired job positions

## Table of contents
README.md --> Project motivation | Goals | Methodology | Results | Conclussions | Limitations | Future Work | Contributions
linkedin_webScraping.ipynb --> The project itself | Sample code used for the project


## Project motivation
#### Introduction
![job_market](https://github.com/XReverte/Webscraping_Linkedin/assets/100844285/85dee40a-12c1-407d-bb74-2204fb732441)
*Image generated by Microsoft Bing (2023). graphic_art [1.0]*

In today's **fast-paced and competitive job market**, breaking into the professional world can often feel like navigating a labyrinth. The abundance of qualified candidates has led recruiters to raise the bar, often seeking individuals who are not just capable but overqualified. Additionally, the advent of Applicant Tracking Systems (ATS) has further complicated the job search process. These systems, designed to streamline hiring, filter applications based on keyword matches, sometimes overlooking a candidate's true potential.

This project emerges as a response to these challenges. It leverages technology to demystify the hiring landscape, providing clarity on **what skills are truly valued**. This clarity not only aids job seekers in honing the right competencies but also in presenting themselves in a manner that aligns with what employers are actively seeking, making the professional world a bit more navigable and accessible.

#### Motivation
This project was conceived as a means to **hone my abilities as a Data Scientist**. By tackling the complexities of *Web Scraping*, *Natural Language Processing* and *Data Analysis*, I aimed to push my boundaries and expand my technical skill set. Moreover, showcasing this project on my portfolio **demonstrates my proactive approach to solving real-world problems**, highlighting my capability and creativity to potential employers.

One of the primary motivations behind this project was to **identify the top skills required in the data science domain**. Understanding which skills are in high demand allows me to prioritize my learning efforts, ensuring that I am well-prepared to meet the expectations of the job market. This enhances my ability to position myself as a competitive candidate in the professional landscape.

#### Disclaimer
To further enhance my skills, I made this project reproducible so it works for any job description and location specified. However, please be aware:

This project was undertaken for **educational purposes** and as a personal tool to assist in my job search. **I do not endorse or take responsibility for any use of this project by others for their own benefit**. Please be aware that web scraping LinkedIn violates their terms and conditions, and any use of this code for scraping LinkedIn is done at your own risk.


## Goals
The primary objective of this project is to **develop an automated, reproducible, versatile, and fault-tolerant system that scrapes LinkedIn to analyze the top skills required for desired job positions**.
- **Automated**: The system should operate autonomously, requiring the user to only input the job position and location. The system will handle the scraping and data analysis without further user intervention.
- **Reproducible**: The process should be repeatable, ensuring consistent results when the same job position and location are queried.
- **Versatile**: The system should work for any desired job position, not limited to a specific role such as Data Scientist.
- **Fault-Tolerant**: To ensure smooth operation, the system must handle errors gracefully, allowing the automation to continue functioning reliably.

These characteristics—automation, reproducibility, versatility, and fault tolerance—are crucial for a useful data science project, **ensuring efficiency, reliability, and broad applicability**.

The system aims to provide a comprehensive analysis of the top skills, **studying their distribution across various dimensions**:
- **Kind of Job Offer**: By querying a broad term like "Data Scientist," the system can identify different roles (e.g., data scientist, data analyst, project manager, machine learning specialist) and understand how top skills differ among these roles.
- **Location**: Similarly, searching by location (e.g., "Spain") can reveal different groups (e.g., Barcelona, Madrid), illustrating regional differences in required skills.
- **Number of Applicants**: The analysis will consider how the top skills vary depending on the number of applicants for a job offer, providing insights into competitive skill sets.
- **Responsibility Level**: The system will explore how required skills vary based on the level of responsibility (e.g., no experience, internship, full-time), offering a nuanced view of career progression requirements.
- **Company Size**: Understanding how the top skills differ depending on the size of the company (e.g., small startups vs. large corporations) will help tailor skill development to specific company profiles.
- **Sector**: The analysis will also cover different industry sectors (e.g., technology, healthcare, finance), showing sector-specific skill demands.

By achieving these goals, the project aims to assist individuals in their personal career development, equipping them with knowledge of in-demand skills tailored to specific job roles, locations, and industry sectors. This comprehensive analysis not only **contributes valuable insights to the broader community of data science professionals** and recruiters but also aspires to **bridge the gap between job seekers and employers**, fostering a more informed and efficient job market.


## Methodology
### Scraping
The scraping component of this project involves several key steps to ensure accurate and efficient data collection from LinkedIn. The entire process is designed to be automated, reproducible, versatile, and fault-tolerant. Here’s an outline of the scraping methodology:

#### Import Libraries:
The necessary libraries for web scraping, such as Selenium for browser automation and Scrapy for HTML parsing, are imported at the beginning. Additional libraries like pandas for data manipulation and datetime for handling date and time are also used.

#### Log In to LinkedIn & Enter Search Criteria:
The Chrome WebDriver is initialized to control the browser. The browser navigates to the LinkedIn login page, and the user is prompted to enter their credentials, (to avoid problems, one should use an **alternative Linkedin account**). After logging in, the user specifies the desired job position and location for the study.

#### Scrape Job Offers:
The script identifies the job offers listed on the search results page. Using predefined XPath expressions to locate the necessary elements, it extracts relevant details such as job title, location, number of applicants, responsibility levels, company size, sector, and skill set.

#### Error Handling:
The script includes mechanisms to handle errors gracefully, such as retrying failed requests and logging errors for later review. This ensures the scraping process continues smoothly even if some elements are not found.

#### Store Data:
Extracted data is compiled into a pandas DataFrame, then it passes through a preliminary adequation process and is exported in .xlsx format for further analysis.

By following these steps, the system can autonomously scrape LinkedIn for job postings, extracting valuable information. This structured approach ensures that the data collected is reliable and comprehensive, providing a solid foundation for the subsequent analysis phase.

#### Disclaimer:
This project was undertaken for educational purposes and as a personal tool to assist in my job search. I made the project reproducible so it works for any job description and location specified. However, **I do not endorse or take responsibility** for any use of this project by others for their own benefit. Please be aware that web scraping LinkedIn violates their terms and conditions, and any use of this code for scraping LinkedIn is done at your own risk.

### Analysis

## Results

## Conclussions

## Limitations

## Future Work

## Contributions

## Tools
